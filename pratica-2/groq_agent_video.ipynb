{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl/78ldodrH7Ch37MM8quL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthur-b-martins/AI-Agents-Lamia/blob/main/pratica-2/groq_agent_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZJWeQveLRt7g",
        "outputId": "68101fc5-f7fe-455f-9615-93f9f2973320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Downloading groq-0.24.0-py3-none-any.whl (127 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/127.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WmugQ7pLs4F"
      },
      "outputs": [],
      "source": [
        "import os  # necessário para trabalhar com o sistema operacional\n",
        "import re  # necessário para trabalhar com regex (no final do código)\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = \"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\"  # define a variável de ambiente com a chave da API do GROQ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Awhc3gcLoVeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FRGYqviSnUwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq  # importa a classe Groq da biblioteca groq\n",
        "\n",
        "client = Groq(  # cria uma instância do cliente Groq\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),  # usa a chave da API armazenada na variável de ambiente\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(  # faz uma requisição para gerar uma resposta do modelo de linguagem\n",
        "    messages=[  # define a lista de mensagens no estilo \"chat\", iniciando com a mensagem do usuário\n",
        "        {\n",
        "            \"role\": \"user\",  # indica que a mensagem foi enviada pelo usuário\n",
        "            \"content\": \"Explain the importance of fast cars\",  # conteúdo da mensagem enviada ao modelo, que no caso foi um exemplo\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\",  # especifica o modelo a ser usado (neste caso, LLaMA 3 com 70 bilhões de parâmetros)\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)  # imprime a resposta gerada pelo modelo (conteúdo da primeira escolha de resposta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFk0cmmRU9GV",
        "outputId": "4f9c48f1-7844-4146-ebe4-2da7ee25fe36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The thrill of the open road and the rush of adrenaline! While not everyone may share the same enthusiasm, there are several reasons why fast cars hold a special place in the hearts of many:\n",
            "\n",
            "1. **Adrenaline rush**: Fast cars provide an exhilarating experience, releasing a rush of adrenaline and endorphins that can be addictive. The thrill of acceleration, cornering, and braking is unmatched, making it a thrilling experience.\n",
            "2. **Sense of freedom**: Fast cars offer a sense of liberation, allowing drivers to feel unencumbered by traffic or road constraints. This emotional high can be empowering, making drivers feel more confident and in control.\n",
            "3. **Innovation and technology**: Fast cars push the boundaries of innovation, driving technological advancements, and improving overall road safety. High-performance vehicles often feature cutting-edge safety features, such as advanced aerodynamics, and improved braking systems.\n",
            "4. **Social status**: Fast cars are often seen as status symbols, reflecting success, sophistication, and exclusivity. Luxury brands like Ferrari, Porsche, and Lamborghini are coveted for their prestige and allure.\n",
            "5. **Driving skills improvement**: Handling a high-performance vehicle requires skill and concentration, encouraging drivers to develop their driving techniques and reflexes. This expertise can translate to improved, safer driving in everyday situations.\n",
            "6. **Competition and racing**: For enthusiasts, high-performance cars enable participation in track days, amateur racing, and professional competitions, fostering a sense of camaraderie and friendly competition.\n",
            "7. **Design and aesthetics**: Sleek, aerodynamic bodies and sleek interior designs make them a work of art, combining style and performance.\n",
            "8. **Nostalgia**: For some, fast cars evoke memories of childhood, watching racing legends like Formula 1 or American muscle cars, fostering a lifelong passion.\n",
            "9. **Business opportunities**: High-performance car industry generates significant revenue, supporting related businesses like motorsports, racing teams, and aftermarket parts manufacturers.\n",
            "\n",
            "While not everyone may share the enthusiasm for fast cars, their significance extends beyond just speed to encompass technology, innovation, social status, driving skills improvement, and nostalgia.\n",
            "\n",
            "What aspect of fast cars resonates with you? Would you like to explore any specific aspect further?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acima foi o primeiro teste da API, para que pudessemos ver o funcionamento do modelo"
      ],
      "metadata": {
        "id": "oUb5Qyj0pQ5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:  # define uma classe chamada Agent, que representa um agente de IA\n",
        "  def __init__(self, client, system):  # método construtor, executado ao criar uma instância da classe\n",
        "    self.client = client  # armazena o cliente da API (por exemplo, uma instância de Groq)\n",
        "    self.system = system  # armazena a mensagem de sistema (instrução inicial para o modelo)\n",
        "    self.messages = []  # inicializa a lista de mensagens do histórico da conversa\n",
        "    if self.system is not None:  # se foi passada uma mensagem de sistema...\n",
        "      self.messages.append({\"role\": \"system\", \"content\": self.system})  # adiciona a mensagem de sistema ao histórico\n",
        "\n",
        "  def __call__(self, message=\"\"):  # permite que a instância do agente seja chamada como uma função, com uma mensagem opcional\n",
        "    if message:  # se uma mensagem foi passada...\n",
        "      self.messages.append({\"role\": \"user\", \"content\": message})  # adiciona a mensagem do usuário ao histórico\n",
        "    result = self.execute()  # executa a chamada ao modelo e obtém a resposta\n",
        "    self.messages.append({\"role\": \"assistant\", \"content\": result})  # adiciona a resposta do modelo ao histórico\n",
        "    return result  # retorna a resposta gerada\n",
        "\n",
        "  def execute(self):  # método que envia o histórico de mensagens ao modelo e retorna a resposta\n",
        "    completion = client.chat.completions.create(  # faz a chamada para gerar uma nova resposta do modelo\n",
        "        messages=self.messages,  # envia o histórico de mensagens\n",
        "        model=\"llama3-70b-8192\"  # define o modelo usado (LLaMA 3 com 70B parâmetros)\n",
        "    )\n",
        "    return completion.choices[0].message.content  # retorna o conteúdo da resposta gerada\n"
      ],
      "metadata": {
        "id": "mIeSohkTeR0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ojEG6pBvpaWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classe do Agente propriamente dita, com as funções principais:\n",
        " - init: para inicializar o agente, com a instância do Groq, e com uma mensagem de sistema.\n",
        " - call: é quando o Agente será chamado, onde se passa a query do usuário. A única parte que não ficou muito clara para mim é que o apresentador do video deixa como opção a mensagem ser vazia, porém na função agent_loop a mensagem nunca é vazia (next_prompt inicializa com a query do usuário e não recebe \"\" em nenhum momento).\n",
        " - execute: retorna a resposta do modelo."
      ],
      "metadata": {
        "id": "ojoWb4V7pfkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define o prompt de sistema, que vai definir como o modelo irá reagir\n",
        "system_prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "get_planet_mass:\n",
        "e.g. get_planet_mass: earth\n",
        "returns weight of the planet in kg\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: What is the mass of Earth times 2?\n",
        "Thought: I need to find the mass of Earth\n",
        "Action: get_planet_mass: Earth\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: 5.972e24\n",
        "\n",
        "Thought: I need to multiply this by 2\n",
        "Action: calculate: 5.972e24 * 2\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: 1,1944×10e25\n",
        "\n",
        "If you have the answer, output it as the Answer.\n",
        "\n",
        "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
        "\n",
        "Now it's your turn:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "YAqGZiEoT9J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(operation: str) -> float:  # define uma função que recebe uma operação matemática em formato de string\n",
        "    return eval(operation)  # avalia a string como uma expressão Python e retorna o resultado (perigoso em código real)\n",
        "\n",
        "# Eu reorganizei este trecho para manter boas práticas de programação\n",
        "PLANET_MASSES = {  # dicionário com as massas dos planetas do sistema solar, em quilogramas (kg)\n",
        "    \"mercury\": 3.285e23,\n",
        "    \"venus\": 4.867e24,\n",
        "    \"earth\": 5.972e24,\n",
        "    \"mars\": 6.39e23,\n",
        "    \"jupiter\": 1.898e27,\n",
        "    \"saturn\": 5.683e26,\n",
        "    \"uranus\": 8.681e25,\n",
        "    \"neptune\": 1.024e26\n",
        "}\n",
        "\n",
        "def get_planet_mass(planet: str) -> float | None:  # define uma função que retorna a massa de um planeta, se ele existir no dicionário\n",
        "    return PLANET_MASSES.get(planet.lower())  # busca a massa do planeta (ignora maiúsculas/minúsculas), ou retorna None se não encontrar\n",
        "\n"
      ],
      "metadata": {
        "id": "MkUfTsxlUtSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neil_tyson = Agent(client=client, system=system_prompt) # define um agente"
      ],
      "metadata": {
        "id": "Y_5kEvzUbtjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = neil_tyson(\"what is the mass of venus?\") # armazena em 'res' a resposta do modelo\n",
        "print(res) # Mostra a resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y287UZucP9l",
        "outputId": "382492b2-570d-4561-8b1d-66c2f594c22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the mass of Venus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é a primeira resposta do nosso agente que pode calcular\n",
        "e pegar a massa dos planetas, e a primeira resposta dele segue de acordo com o\n",
        "prompt de sistema, onde determina que primeiro ele deve pensar o que será necessário fazer para resolver o problema.\n"
      ],
      "metadata": {
        "id": "3fBwb6h1kUmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = neil_tyson.messages # armazena em 'res' todas as mensagens\n",
        "print(res) # mostra as mensagens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y82fcdAvfYok",
        "outputId": "7da0fcb1-d54c-4e09-e7e6-37e438d14acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: earth\\nreturns weight of the planet in kg\\n\\nExample session:\\n\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE \\n\\nYou will be called again with this:\\n\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this: \\n\\nObservation: 1,1944×10e25\\n\\nIf you have the answer, output it as the Answer.\\n\\nAnswer: The mass of Earth times 2 is 1,1944×10e25.\\n\\nNow it's your turn:\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_loop(max, system, query):  # define uma função que executa um loop com o agente, recebendo: número máximo de iterações, sistema (instrução) e pergunta inicial\n",
        "  agent = Agent(client, system)  # cria uma instância do agente, passando o cliente e a mensagem de sistema\n",
        "  next_prompt = query  # define a primeira entrada (pergunta) como o prompt inicial\n",
        "  tools = ['calculate', 'get_planet_mass']  # define as ferramentas disponíveis que o agente pode usar\n",
        "\n",
        "  for i in range(max):  # executa um loop até o número máximo de iterações\n",
        "    result = agent(next_prompt)  # envia o prompt atual para o agente e recebe a resposta\n",
        "    print(result)  # imprime a resposta do agente\n",
        "\n",
        "    if \"PAUSE\" in result:  # se a resposta contém a palavra \"PAUSE\", significa que o agente quer executar uma ação antes de continuar\n",
        "      action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)  # usa regex para extrair o nome da ferramenta e o argumento\n",
        "      chosen_tool = action[0][0]  # extrai o nome da ferramenta da tupla encontrada\n",
        "      arg = action[0][1]  # extrai o argumento fornecido\n",
        "\n",
        "      if chosen_tool in tools:  # se a ferramenta for permitida...\n",
        "        tool_response = eval(f\"{chosen_tool}('{arg}')\")  # executa a função com o argumento\n",
        "        next_prompt = f\"Observation: {tool_response}\"  # cria a próxima entrada baseada na resposta da ferramenta\n",
        "\n",
        "      else:\n",
        "        next_prompt = \"Observation: tool not found\"  # se a ferramenta não for reconhecida\n",
        "\n",
        "      print(next_prompt)  # imprime a observação gerada\n",
        "      continue  # pula para a próxima iteração do loop\n",
        "\n",
        "    if \"Answer\" in result:  # se a resposta contém \"Answer\", o agente chegou na resposta\n",
        "      break  # encerra o loop\n"
      ],
      "metadata": {
        "id": "zM3UcZfbkKqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho simula um ciclo de raciocínio iterativo: o agente pensa, pode decidir pausar e chamar uma função externa (no caso uma calculadora ou massa de um planeta), a observação é o retorno da resposta da ferramenta, adicionada como mensagem, e então continua o raciocínio com base nessa observação,\n",
        "até que o agente encontre a resposta da pergunta inicial, que teoricamente seria feita pelo usuário.\n",
        "\n"
      ],
      "metadata": {
        "id": "bq5FJ5Jzl7qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(10, system_prompt, \"What is the mass of mercury times 3?\") # chamando a função com máximo de 10 iterações,\n",
        "# com o prompt de sistema definido no inicio (Pensar, Agir, Receber a observação, até obter a resposta)\n",
        "# e com a query do 'usuário'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqi-gD-Xr9p1",
        "outputId": "f34f8e1b-75ea-4611-aa04-2b54cf765a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the mass of Mercury\n",
            ".\n",
            "\n",
            "Action: get_planet_mass: mercury\n",
            "PAUSE\n",
            "Observation: 3.285e+23\n",
            "Thought: I need to multiply this by 3\n",
            "\n",
            "Action: calculate: 3.285e+23 * 3\n",
            "PAUSE\n",
            "Observation: 9.854999999999999e+23\n",
            "Thought: I have the answer\n",
            "!\n",
            "\n",
            "Answer: The mass of mercury times 3 is 9.854999999999999e+23.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E por fim temos o resultado do nosso agente, agindo conforme o prompt de sistema, e dando a saída correta para o usuário. Podemos ver todo seu ciclo de pensamento."
      ],
      "metadata": {
        "id": "8kLDqhV8m2K5"
      }
    }
  ]
}